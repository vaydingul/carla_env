experiment_type: "train_policy_model"
seed: 42
checkpoint_path: "pretrained_models/"
log_path: ~ #"logs/"

num_time_step_previous: &previous 20
num_time_step_future: &future 10
sequence_length: &sequence_length 30
num_workers: &num_workers 5
num_gpu: &num_gpu 1
bev_agent_channel: &bev_agent_channel 7
bev_vehicle_channel: &bev_vehicle_channel 6
bev_selected_channels: &bev_selected_channels [0, 1, 2, 3, 4, 5, 6, 11]
bev_calculate_offroad: &bev_calculate_offroad false
# Dataset related parameters for training
dataset_train:
  type: "TorchDataset"
  config:
    data_path: "/home/volkan/Documents/Codes/carla_env/data/ground_truth_bev_model_dummy_data_20Hz_multichannel_bev_dense_traffic_converted"
# Dataloader related parameters for training
dataloader_train:
  batch_size: 120
  shuffle: true
  num_workers: *num_workers
  drop_last: true

# Dataset related parameters for validation
dataset_val:
  type: "TorchDataset"
  config:
    data_path: "/home/volkan/Documents/Codes/carla_env/data/ground_truth_bev_model_dummy_data_20Hz_multichannel_bev_dense_traffic_converted"

# Dataloader related parameters for validation
dataloader_val:
  batch_size: 120
  shuffle: false
  num_workers: *num_workers
  drop_last: true

cost:
  type: "extended_bev"
  config:
    image_width: 192
    image_height: 192
    reduction: "sum"
    mask_alpha: 1.1
    decay_factor: 0.99
    vehicle_width: 2.1
    vehicle_length: 4.9
    pixels_per_meter: 5
    longitudinal_offset: 0.125
    longitudinal_scaler: 1
    longitudinal_speed_offset: 0.125
    longitudinal_speed_scaler: 2.0
    lateral_offset: 1.0
    lateral_scaler: 0.5

# Training related parameters
training:
  num_epochs: 100
  num_gpu: *num_gpu
  master_port: "12345"
  weighted_sampling: false
  sigmoid_before_loss: false
  optimizer:
    type: "Adam"
    parameters: [policy]
    config:
      lr: 0.0001
      # weight_decay: 0.0001

  save_interval: 100
  val_interval: 1
  num_time_step_future: *future
  num_time_step_previous: *previous
  gradient_clip:
    enable: true
    type: "norm"
    value: 1

  # Scheduler related parameters
  scheduler:
    enable: false
    type: "ReduceLROnPlateau"
    config:
      patience: 10
      factor: 0.5
      min_lr: 0.0000001

  binary_occupancy:
    enable: false
    threshold: 5.0

  use_world_forward_model_encoder_output_as_world_state: true
  use_ground_truth: true
  debug_render: true

  renderer:
    width: 1300
    height: 1000
    channel: 3
    background_color: [0, 0, 0]
    font_scale: 0.5
    font_color: [255, 255, 255]
    font_thickness: 1
    cursor: [0, 0]
    name: Policy Model Training
    show: false
    save: true
    create_date_time_path: true
    save_path: figures/env_debug/train_policy/

  cost_weight:
    road_cost: 0.0
    road_on_cost: 0.0
    road_off_cost: 0.1
    road_red_yellow_cost: 0.1
    road_green_cost: -0.1
    vehicle_cost: 0.1
    lane_cost: 0.1
    offroad_cost: 0.1
    action_mse: 10.0
    action_l1: 0.0
    action_jerk: 0.0
    target_progress: -10.0
    target_remainder: 10.0
    ego_state_mse: 0.0
    world_state_mse: 0.0

ego_forward_model:
  type: "KinematicBicycleModel"
  config:
    dt: 0.05

# World forward model related parameters
world_forward_model:
  type: "WorldBEVModel"
  config:
    input_shape: [8, 192, 192]
    latent_size: 128
    hidden_channel: 256
    output_channel: 512
    num_encoder_layer: 4
    num_probabilistic_encoder_layer: 2
    dropout: 0.1
    num_time_step_previous: *previous
    num_time_step_future: 1 #*future

# Policy model related parameters
policy_model:
  type: "FusedPolicyModel"
  config:
    input_shape_world_state: [8, 192, 192]
    input_ego_location: 0
    input_ego_yaw: 0
    input_ego_speed: 1
    action_size: 2
    use_command: true
    command_size: 6
    use_target: true
    target_location_size: 2
    use_occupancy: false
    occupancy_size: 8
    hidden_size: 256
    layers: 2
    delta_target: true
    dropout: 0.0

wandb_ego_forward_model:
  enable: false
  link: vaydingul/mbl-refactored/3vfihnmu
  checkpoint_number: 99

wandb_world_forward_model:
  enable: false
  link: vaydingul/mbl-refactored/1qa8f9wd
  checkpoint_number: 47

# Wandb related parameters
wandb:
  enable: false
  resume: false
  resume_checkpoint_number: 0
  project: "mbl-refactored"
  group: "train-policy-model-multi-step-20Hz"
  name: "20-10-20Hz"
  id: ~
  notes: "Policy model with 20Hz data and 20 time steps in the past and 10 time step in the future. It can work with every model that works in 20Hz."
